{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from sklearn import neighbors,preprocessing \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_absolute_percentage_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #表格化resd_csv\n",
    "# train_data=pd.read_csv('./adult/adult.data',header=0,names=['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','class'])\n",
    "# test_data=pd.read_csv('./adult/adult.test',header=0,names=['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','class'])\n",
    "# #?換成NAN\n",
    "# train_data=train_data.replace(' ?',np.nan)\n",
    "# test_data=test_data.replace(' ?',np.nan)\n",
    "# #找'workclass','occupation','native-country'各自的眾數，NaN替換成眾數\n",
    "# train_data['workclass']=train_data['workclass'].fillna((train_data['workclass'].mode()[0]))\n",
    "# train_data['occupation']=train_data['occupation'].fillna((train_data['occupation'].mode()[0]))\n",
    "# train_data['native-country']=train_data['native-country'].fillna((train_data['native-country'].mode()[0]))\n",
    "# test_data['workclass']=test_data['workclass'].fillna((test_data['workclass'].mode()[0]))\n",
    "# test_data['occupation']=test_data['occupation'].fillna((test_data['occupation'].mode()[0]))\n",
    "# test_data['native-country']=test_data['native-country'].fillna((test_data['native-country'].mode()[0]))\n",
    "# #去除class裡的.跟空白鍵\n",
    "# # train_data=train_data.apply(lambda x: x.replace(' ', ''))\n",
    "# # test_data=test_data.apply(lambda x: x.replace(' ', ''))\n",
    "# # test_data['class'] = test_data['class'].apply(lambda x: x.replace('>50K.','>50K'))\n",
    "# # test_data['class'] = test_data['class'].apply(lambda x: x.replace('<=50K.','<=50K'))\n",
    "# # labelencoder = LabelEncoder()\n",
    "# # labelencoder.fit_transform(test_data['class'])\n",
    "# #刪除意思相近的欄位\n",
    "# train_data=train_data.drop(labels=['education-num'],axis='columns')\n",
    "# test_data=test_data.drop(labels=['education-num'],axis='columns')\n",
    "# #刪除較無意義的欄位\n",
    "# train_data=train_data.drop(labels=['fnlwgt'],axis='columns')\n",
    "# test_data=test_data.drop(labels=['fnlwgt'],axis='columns')\n",
    "# # #刪掉重複的資料\n",
    "# train_data=train_data.drop_duplicates() \n",
    "# test_data=test_data.drop_duplicates() \n",
    "# #one hot encoding\n",
    "# train_data=pd.get_dummies(train_data,columns=['workclass','education','marital-status','occupation','relationship','race','sex','native-country','class'],dtype=int)\n",
    "# test_data=pd.get_dummies(test_data,columns=['workclass','education','marital-status','occupation','relationship','race','sex','native-country','class'],dtype=int)\n",
    "# #test_data的feature缺少了'native-country_ Holand-Netherlands'這個欄位，將此欄位補上後，值填0，_並用get_loc找出位置排序好\n",
    "# test_data.insert(loc=76,column='native-country_ Holand-Netherlands',value=0)\n",
    "# #StandardScaler\n",
    "# train_data['age'] = (train_data['age']-train_data['age'].mean())/train_data['age'].std()\n",
    "# train_data['capital-gain'] = (train_data['capital-gain']-train_data['capital-gain'].mean())/train_data['capital-gain'].std()\n",
    "# train_data['capital-loss'] = (train_data['capital-loss']-train_data['capital-loss'].mean())/train_data['capital-loss'].std()\n",
    "# train_data['hours-per-week'] = (train_data['hours-per-week']-train_data['hours-per-week'].mean())/train_data['hours-per-week'].std()\n",
    "# test_data['age'] = (test_data['age']-test_data['age'].mean())/test_data['age'].std()\n",
    "# test_data['capital-gain'] = (test_data['capital-gain']-test_data['capital-gain'].mean())/test_data['capital-gain'].std()\n",
    "# test_data['capital-loss'] = (test_data['capital-loss']-test_data['capital-loss'].mean())/test_data['capital-loss'].std()\n",
    "# test_data['hours-per-week'] = (test_data['hours-per-week']-test_data['hours-per-week'].mean())/test_data['hours-per-week'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: Train (32561, 15) , Test (16281, 15)\n",
      "After Dropping: Train (32537, 15) , Test (16276, 15)\n"
     ]
    }
   ],
   "source": [
    "# read dataframe\n",
    "train_data = pd.read_csv('./adult/adult.data', header= None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "test_data = pd.read_csv('./adult/adult.test', header= None, skiprows=1, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "originTest = test_data\n",
    "\n",
    "print(\"Original data: Train\", train_data.shape, \", Test\", test_data.shape)\n",
    "\n",
    "# drop duplicate value\n",
    "train_data.drop_duplicates(inplace=True)\n",
    "test_data.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"After Dropping: Train\", train_data.shape, \", Test\", test_data.shape)\n",
    "# education and education-num have same meaning\n",
    "train_data.drop(['education'], axis = 1, inplace = True)\n",
    "test_data.drop(['education'], axis = 1, inplace = True)\n",
    "\n",
    "# fnlwgt is not important feature\n",
    "train_data.drop(['fnlwgt'], axis = 1, inplace = True)\n",
    "test_data.drop(['fnlwgt'], axis = 1, inplace = True)\n",
    "\n",
    "# remove the space\n",
    "train_data = train_data.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "test_data = test_data.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "# replace the NAN into mode value\n",
    "train_data['workclass'] = train_data['workclass'].replace(\"?\", train_data['workclass'].mode()[0])\n",
    "train_data['occupation'] = train_data['occupation'].replace(\"?\",train_data['occupation'].mode()[0])\n",
    "train_data['native-country'] = train_data['native-country'].replace(\"?\",train_data['native-country'].mode()[0])\n",
    "\n",
    "\n",
    "test_data['workclass'] = test_data['workclass'].replace(\"?\", test_data['workclass'].mode()[0])\n",
    "test_data['occupation'] = test_data['occupation'].replace(\"?\",test_data['occupation'].mode()[0])\n",
    "test_data['native-country'] = test_data['native-country'].replace(\"?\",test_data['native-country'].mode()[0])\n",
    "\n",
    "# Label Encoding\n",
    "# tranfer the value of class(income) into int(1 or 0)\n",
    "# >50K is 1, <=50K is 0\n",
    "train_data['income'] = train_data['income'].apply(lambda x: 1 if x == \">50K\" else 0)\n",
    "test_data['income'] = test_data['income'].apply(lambda x: 1 if x == \">50K\" else 0)\n",
    "\n",
    "# One Hot Encoding (Dummies)\n",
    "trainData_dum = pd.get_dummies(train_data, columns=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], dtype=int)\n",
    "testData_dum = pd.get_dummies(test_data, columns=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], dtype=int)\n",
    "pd.DataFrame(trainData_dum)\n",
    "\n",
    "#在讀熱編碼後會依照有名目之欄位產生資料，train_data比test_data多出了該欄位，故將test_data新增該欄位，讓兩個資料集欄位相同。\n",
    "testData_dum['native-country_Holand-Netherlands'] = 0\n",
    "\n",
    "# Normalization(z-score)\n",
    "numerical_columns = ['age','education-num','capital-gain','capital-loss']\n",
    "scaler = preprocessing.StandardScaler()\n",
    "trainData_dum[numerical_columns] = scaler.fit_transform(trainData_dum[numerical_columns])\n",
    "testData_dum[numerical_columns] = scaler.transform(testData_dum[numerical_columns])\n",
    "\n",
    "\n",
    "## replace \"&\" into \"and\" (for graph)\n",
    "trainData_dum = trainData_dum.rename(columns={'native-country_Trinadad&Tobago': 'native-country_Trinadad_and_Tobago'})\n",
    "testData_dum = testData_dum.rename(columns={'native-country_Trinadad&Tobago': 'native-country_Trinadad_and_Tobago'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立模型\n",
    "train_X, test_X, train_y, test_y = trainData_dum.drop(columns=['hours-per-week'],axis=1),testData_dum.drop(columns=['hours-per-week'],axis=1),trainData_dum['hours-per-week'],testData_dum['hours-per-week']\n",
    "# neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "# neigh.fit(train_X.values, train_y) #Here x.values will have only values without headers\n",
    "# pred_y=neigh.predict(test_X.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN績效(RMSE，MAE、R-Squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_score=[]\n",
    "R2=[]\n",
    "RMSE=[]\n",
    "MAPE=[]\n",
    "i_array=[]\n",
    "for i in range(20,30):\n",
    "    print(\"neighbors numbers:\",i)\n",
    "    i_array.append(i)\n",
    "    startT = time.time()\n",
    "    neigh = KNeighborsRegressor(n_neighbors=i,leaf_size=35,n_jobs=-1)\n",
    "    neigh.fit(train_X.values, train_y) #Here x.values will have only values without headers\n",
    "    endT = time.time()\n",
    "    pred_y=neigh.predict(test_X.values)\n",
    "\n",
    "    train_data_score_data=neigh.score(train_X.values, train_y)\n",
    "    train_data_score.append(train_data_score_data)\n",
    "    R2_data=r2_score(test_y, pred_y)\n",
    "    R2.append(R2_data)\n",
    "    RMSE_data=np.sqrt(mean_squared_error(test_y,pred_y))\n",
    "    RMSE.append(RMSE_data)\n",
    "    MAPE_data=mean_absolute_percentage_error(test_y,pred_y)\n",
    "    MAPE.append(MAPE_data)\n",
    "\n",
    "    print(f\"train_data score:{train_data_score_data:.3f}\")\n",
    "    print(f\"R2:{R2_data:.5f}\")\n",
    "    print(f\"RMSE:{RMSE_data:.5f}\")\n",
    "    print(f\"MAPE:{MAPE_data:.5f}%\")\n",
    "    print('執行時間:', endT-startT)\n",
    "    print('------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "plt.plot(i_array,R2)\n",
    "bottom,top= plt.ylim()\n",
    "print(f\"Top value:{top:.5f}, Bottom value:{bottom:.5f}\")\n",
    "plt.xlabel('max_depth',fontsize=12)\n",
    "plt.ylabel('R2',fontsize=12)\n",
    "plt.title('RandomForest')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(i_array,RMSE)\n",
    "bottom,top= plt.ylim()\n",
    "print(f\"Top value:{top:.5f}, Bottom value:{bottom:.5f}\")\n",
    "plt.xlabel('max_depth',fontsize=12)\n",
    "plt.ylabel('RMSE',fontsize=12)\n",
    "plt.title('RandomForest')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(i_array,MAPE)\n",
    "bottom,top= plt.ylim()\n",
    "print(f\"Top value:{top:.5f}, Bottom value:{bottom:.5f}\")\n",
    "plt.xlabel('max_depth',fontsize=12)\n",
    "plt.ylabel('MAPE',fontsize=12)\n",
    "plt.title('RandomForest')\n",
    "plt.show()\n",
    "\n",
    "#plot_scatterplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=pred_y, y=test_y)\n",
    "plt.plot([min(test_y), max(test_y)], [min(test_y), max(test_y)], linestyle='--', color='red', linewidth=2, label='Ideal line (y=x)')\n",
    "plt.title(f'Predicted vs. Actual Values (R-squared: {r2_score(test_y,pred_y):.2f})')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# #from sklearn import svm\n",
    "# import time\n",
    "\n",
    "# startT = time.time()\n",
    "# train_X, test_X, train_y, test_y = trainData_dum.drop(columns=['hours-per-week'],axis=1), test_data.drop(columns=['hours-per-week'],axis=1), trainData_dum['hours-per-week'], test_data['hours-per-week']\n",
    "\n",
    "# # build SVM model\n",
    "# # O_SVMmodel = SVR(C = 200, max_iter = 1000000, cache_size = 1000, gamma='auto') #,n_jobs=2 \n",
    "# O_SVMmodel = SVR(C = 200, max_iter = 1000000, cache_size = 1000, gamma='auto') #,n_jobs=2 \n",
    "# # Training\n",
    "# O_SVMmodel = O_SVMmodel.fit(train_X, train_y.ravel())\n",
    "\n",
    "# endT = time.time()\n",
    "# print('執行時間:', endT-startT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted = O_SVMmodel.predict(test_X)\n",
    "  \n",
    "# r2 = r2_score(test_y, predicted)\n",
    "# print('R2 Score:{0}'.format(r2))\n",
    "\n",
    "# rmse = np.sqrt(mean_squared_error(test_y, predicted))\n",
    "# print('RMSE:{0}'.format(rmse))\n",
    "\n",
    "# mape = mean_absolute_percentage_error(test_y, predicted)\n",
    "# print('MAPE:{0}'.format(mape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mb207\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\mb207\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "model = SVR(C=200,max_iter=1000000,cache_size=1000)\n",
    "model=model.fit(train_X,train_y.ravel())  #fit the model\n",
    "pred_y=model.predict(test_X) #make prediction on test set\n",
    "end=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is: 12.805\n",
      "MAPE value is: 38.81 %\n",
      "r_squared_value: -1.394\n",
      "執行時間: 515.6926181316376\n"
     ]
    }
   ],
   "source": [
    "error_RMSE = np.sqrt(mean_squared_error(test_y,pred_y)) #calculate rmse\n",
    "error_MAPE = mean_absolute_percentage_error(test_y,pred_y)\n",
    "error_r2 = r2_score(pred_y,test_y) \n",
    "\n",
    "print('RMSE value is:', round(error_RMSE,3))\n",
    "print('MAPE value is:', round((error_MAPE*100),2),'%')\n",
    "print('r_squared_value:', round(error_r2,3))\n",
    "print('執行時間:',end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
