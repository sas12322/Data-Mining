{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, x, y, attribute_list, node_type):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        self.attributes_list = attribute_list\n",
    "        self.best_attribute = None\n",
    "        self.split_criterion = None\n",
    "        self.split_up_down = None\n",
    "        self.node_type = node_type\n",
    "        self.leaf_label = None\n",
    "        self.depth = 0\n",
    "        self.children = []\n",
    "        self.parent = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.depth < other.depth\n",
    "\n",
    "    def predict_leaf_class(self):\n",
    "        \"\"\"\n",
    "            Computes the frequency of classes in partition D, output the leaf node label predicted class\n",
    "        :return: pred_class\n",
    "        \"\"\"\n",
    "        # takes frequency of classes in D to determine the majority class to set as output leaf label\n",
    "        freq_classes = collections.Counter(self.labels)  # [4]\n",
    "        pred_class = max(freq_classes, key=freq_classes.get)\n",
    "        self.leaf_label = pred_class\n",
    "        return pred_class\n",
    "\n",
    "    def print_node(self):\n",
    "        \"\"\"\n",
    "            Print node values\n",
    "        \"\"\"\n",
    "        print('best att-', self.best_attribute, 'split_crit-', self.split_up_down, self.split_criterion, 'type-',\n",
    "              self.node_type, 'depth-',\n",
    "              self.depth, 'class label-', self.leaf_label)\n",
    "\n",
    "    def copy(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class C45Tree:\n",
    "    def __init__(self, attributes, data):\n",
    "        self.tree_nodes = []\n",
    "        self.depth = 0\n",
    "        self.num_leaves = 0\n",
    "        self.root_node = None\n",
    "        self.attributes = attributes[:-1]\n",
    "        self.dataset = data\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "            Helper function to grow tree recursively, creates root node for the tree and initializes the recursion for\n",
    "            training the tree.\n",
    "        :param x_train:\n",
    "        :param y_train:\n",
    "        \"\"\"\n",
    "        # create root node, put data partition in node\n",
    "        self.root_node = Node(x_train, y_train, self.attributes, 'root')\n",
    "        self.tree_nodes.append(self.root_node)\n",
    "        # call grow_tree with root node as base\n",
    "        self.grow_tree(self.root_node, self.attributes, (x_train, y_train))\n",
    "\n",
    "    def grow_tree(self, prev_node, attribute_list, D):\n",
    "        \"\"\"\n",
    "            Uses C4.5 decision tree algorithm to grow a tree during training, based on pseudocode from [1].\n",
    "        :param attribute_list:\n",
    "        :param D:\n",
    "        :param prev_node:\n",
    "        :return: N, the new node\n",
    "        \"\"\"\n",
    "        if prev_node is not None and prev_node.parent is not None:\n",
    "            if prev_node not in prev_node.parent.children:\n",
    "                prev_node.parent.children.append(prev_node)\n",
    "\n",
    "        # check for termination cases\n",
    "        # check if all tuples in D are in the same class\n",
    "        if self.check_same_class_labels(D[1]):\n",
    "            N = Node(D[0], D[1], attribute_list, 'leaf')\n",
    "            N.depth = prev_node.depth + 1\n",
    "            N.predict_leaf_class()  # determine the class of the leaf\n",
    "            N.best_attribute = str(prev_node.best_attribute)\n",
    "            N.split_up_down = prev_node.split_up_down\n",
    "            N.split_criterion = prev_node.split_criterion\n",
    "            self.tree_nodes.append(N)\n",
    "            prev_node.children.append(N)\n",
    "            N.parent = prev_node\n",
    "            return N\n",
    "\n",
    "        # check if attribute list is empty, do majority voting on class\n",
    "        if not attribute_list:\n",
    "            N = Node(D[0], D[1], attribute_list, 'leaf')\n",
    "            N.depth = prev_node.depth + 1\n",
    "            N.predict_leaf_class()  # determine the class of the leaf\n",
    "            N.best_attribute = str(prev_node.best_attribute)\n",
    "            N.split_criterion = prev_node.split_criterion\n",
    "            N.split_up_down = prev_node.split_up_down\n",
    "            self.tree_nodes.append(N)\n",
    "            prev_node.children.append(N)\n",
    "            N.parent = prev_node\n",
    "            return N\n",
    "\n",
    "        # create new node\n",
    "        N = Node(D[0], D[1], attribute_list, 'node')\n",
    "        N.depth = prev_node.depth + 1\n",
    "        N.parent = prev_node\n",
    "        # conduct attribute selection method, label node with the criterion\n",
    "        best_attribute, crit_split_val = self.attribute_selection_method(D, attribute_list)\n",
    "\n",
    "        N.best_attribute = best_attribute  # label node with best attribute\n",
    "        N.split_criterion = crit_split_val  # for discrete\n",
    "        if best_attribute == '':\n",
    "            # early stop\n",
    "            N.best_attribute = str(best_attribute)\n",
    "            N.split_up_down = None\n",
    "            N.node_type = 'leaf'\n",
    "            N.data = prev_node.data\n",
    "            N.labels = prev_node.labels\n",
    "            N.predict_leaf_class()\n",
    "            self.tree_nodes.append(N)\n",
    "            prev_node.children.append(N)\n",
    "            return N\n",
    "\n",
    "        # remove split attribute from attribute list\n",
    "        if best_attribute in attribute_list:\n",
    "            attribute_list.remove(best_attribute)\n",
    "\n",
    "        # check if attribute is discrete NOTE THIS LINE NEEDS TO BE MODIFIED FOR DIFFERENT DATASET\n",
    "        if len(self.dataset[\n",
    "                   best_attribute].unique()) > 5:  # max 5 discrete categories in attributes from Thyroid set\n",
    "            # continuous, divide up data at mid point of the values ai + ai1/2\n",
    "            l_part, r_part, split_val = self.continuous_attribute_data_partition(D, best_attribute)\n",
    "            N.split_criterion = split_val\n",
    "            N.split_up_down = 'UP'\n",
    "            l_child = self.grow_tree(N, attribute_list, l_part)  # upper -> att_val > split_val\n",
    "            N_V = Node(D[0], D[1], attribute_list, 'node')\n",
    "            N_V.depth = N.depth\n",
    "            N_V.best_attribute = best_attribute\n",
    "            N_V.split_criterion = split_val\n",
    "            N_V.parent = prev_node\n",
    "            N_V.split_up_down = 'DOWN'\n",
    "            r_child = self.grow_tree(N_V, attribute_list, r_part)  # lower -> att_val <= split_val\n",
    "            N.children.append(l_child)\n",
    "            N_V.children.append(r_child)\n",
    "            N.parent = prev_node\n",
    "            self.tree_nodes.append(N)\n",
    "            self.tree_nodes.append(N_V)\n",
    "            prev_node.children.append(N)\n",
    "            prev_node.children.append(N_V)\n",
    "            return N\n",
    "        else:\n",
    "            # discrete, partition based on unique values of attribute to create nodes for recursion\n",
    "            vals = self.dataset[best_attribute].unique()  # D[0][best_attribute].unique()\n",
    "            for v in list(vals):\n",
    "                data_part = self.partition_data(D, best_attribute, v)\n",
    "\n",
    "                if not data_part:  # TOGGLED TO EMPTY CAUSES 2 LEAVES ONLY TO BE MADE ** check this\n",
    "                    # majority class leaf node computed of D\n",
    "                    L = Node(D[0], D[1], attribute_list, 'leaf')\n",
    "                    L.depth = N.depth + 1\n",
    "                    L.best_attribute = best_attribute\n",
    "                    L.split_criterion = v\n",
    "                    L.predict_leaf_class()  # determine the class of the leaf\n",
    "                    self.tree_nodes.append(L)\n",
    "                    N.children.append(L)\n",
    "                    L.parent = N\n",
    "                else:\n",
    "                    # recursion\n",
    "                    N_V = Node(D[0], D[1], attribute_list, 'node')\n",
    "                    N_V.depth = N.depth\n",
    "                    N_V.best_attribute = best_attribute\n",
    "                    N_V.split_criterion = v\n",
    "                    N_V.parent = prev_node\n",
    "                    N_V.parent.children.append(N_V)\n",
    "                    child = self.grow_tree(N_V, attribute_list, data_part)\n",
    "\n",
    "        if N not in self.tree_nodes:\n",
    "            self.tree_nodes.append(N)\n",
    "            prev_node.children.append(N)\n",
    "        return N\n",
    "\n",
    "    def continuous_attribute_data_partition(self, D, attribute):\n",
    "        \"\"\"\n",
    "            Creates data partitions (left and right) for continuous attributes, computing the mid point that\n",
    "            enables the best information gain ratio to be calculated from the partition.\n",
    "        :param D:\n",
    "        :param attribute:\n",
    "        :return: l_part, r_part, split_val\n",
    "        \"\"\"\n",
    "        # sort the data, find the value that will gain the max info gain ratio\n",
    "        data = D[0].sort_values(by=[attribute])\n",
    "        split_val = 0\n",
    "        best_igr = 0\n",
    "        l_part = []\n",
    "        r_part = []\n",
    "\n",
    "        for i in range(0, len(data) - 1):\n",
    "            mid_point = (float(data.iloc[i][attribute]) + float(data.iloc[i + 1][attribute])) / 2\n",
    "            left_d = D[0].loc[pd.to_numeric(D[0][attribute]) > mid_point]\n",
    "            left_idx = D[0].index[pd.to_numeric(D[0][attribute]) > mid_point]\n",
    "            left_y = D[1].loc[left_idx]\n",
    "            right_d = D[0].loc[pd.to_numeric(D[0][attribute]) <= mid_point]\n",
    "            right_idx = D[0].index[pd.to_numeric(D[0][attribute]) <= mid_point]\n",
    "            right_y = D[1].loc[right_idx]\n",
    "            igr = self.compute_info_gain_ratio_continuous(D, left_y, right_y)\n",
    "\n",
    "            if igr >= best_igr:\n",
    "                best_igr = igr\n",
    "                split_val = mid_point\n",
    "                l_part = (left_d, left_y)\n",
    "                r_part = (right_d, right_y)\n",
    "\n",
    "        return l_part, r_part, split_val\n",
    "\n",
    "    def compute_info_gain_ratio_continuous(self, D, left_y, right_y):\n",
    "        \"\"\"\n",
    "            Computes the information gain ratio for a continuous attribute partition\n",
    "        :return info_gain_ratio\n",
    "        \"\"\"\n",
    "        l_y = left_y\n",
    "        r_y = right_y\n",
    "\n",
    "        dataset_entropy = self.data_entropy(D[1])\n",
    "        l_part_entropy = self.data_entropy(l_y)\n",
    "        l_p_j = float(len(l_y) / len(D))\n",
    "        l_ent = l_p_j * l_part_entropy\n",
    "        r_part_entropy = self.data_entropy(r_y)\n",
    "        r_p_j = float(len(r_y) / len(D))\n",
    "        r_ent = r_p_j * r_part_entropy\n",
    "\n",
    "        split_info = - self.split_info(l_p_j) - self.split_info(r_p_j)\n",
    "        att_ent = l_ent + r_ent\n",
    "\n",
    "        if split_info == 0:  # prevent division by zero for ratio\n",
    "            return 0\n",
    "        else:\n",
    "            info_gain = self.information_gain(dataset_entropy, att_ent)\n",
    "            info_gain_ratio = self.information_gain_ratio(info_gain,\n",
    "                                                          split_info)\n",
    "        return info_gain_ratio\n",
    "\n",
    "    @staticmethod\n",
    "    def check_same_class_labels(labels):\n",
    "        \"\"\"\n",
    "            Checks set of labels to ensure they are of the same class type\n",
    "        :param labels:\n",
    "        :return: bool\n",
    "        \"\"\"\n",
    "        if len(set(labels)) == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def attribute_selection_method(self, D, attribute_list):\n",
    "        \"\"\"\n",
    "            Attribute Selection Method for decision tree as discussed in [1] (Figure 8.3), selects attribute that\n",
    "            provides the best information gain ratio as a result.\n",
    "        :param D:\n",
    "        :param attribute_list:\n",
    "        :return: best_attribute\n",
    "        \"\"\"\n",
    "        best_attribute = ''\n",
    "        dataset_entropy = self.data_entropy(D[1])\n",
    "        best_info_gain_ratio = 0.0\n",
    "        split_val = ''\n",
    "\n",
    "        for attribute in attribute_list:\n",
    "            # a_idx = self.attributes.get(attribute) MIGHT NEED THIS\n",
    "            v = D[0][attribute].unique()  # find v distinct values of attribute\n",
    "            att_ent = 0.0\n",
    "            split_info = 0.0\n",
    "            curr_val = ''\n",
    "            val_ent = 0.0\n",
    "            for val in v:\n",
    "                data_partition = self.partition_data(D, attribute, val)\n",
    "                partition_labels = data_partition[1]\n",
    "                part_entropy = self.data_entropy(partition_labels)\n",
    "                p_j = float(len(data_partition[1]) / len(D[1]))\n",
    "                att_ent = att_ent + (p_j * part_entropy)\n",
    "                split_info = split_info - self.split_info(p_j)\n",
    "\n",
    "                if part_entropy > val_ent:\n",
    "                    val_ent = part_entropy\n",
    "                    curr_val = val\n",
    "\n",
    "            # Best Attribute checks\n",
    "            if split_info == 0:  # prevent division by zero for ratio\n",
    "                continue\n",
    "            else:\n",
    "                info_gain = self.information_gain(dataset_entropy, att_ent)\n",
    "                info_gain_ratio = self.information_gain_ratio(info_gain,\n",
    "                                                              split_info)  # calculate info gain ratio to select\n",
    "\n",
    "            # compare the top performing attribute info gain ratio\n",
    "            if info_gain_ratio > best_info_gain_ratio:\n",
    "                best_info_gain_ratio = info_gain_ratio\n",
    "                best_attribute = attribute\n",
    "                split_val = curr_val\n",
    "        return best_attribute, split_val\n",
    "\n",
    "    def class_prob(self, feature_label, labels):\n",
    "        \"\"\"\n",
    "            Computes class probabilities from labels\n",
    "        :param feature_label:\n",
    "        :param labels:\n",
    "        :return: p\n",
    "        \"\"\"\n",
    "        c = collections.Counter(labels)  # [4]\n",
    "        p = c[feature_label] / len(labels)\n",
    "        return float(p)\n",
    "\n",
    "    def data_entropy(self, labels):\n",
    "        \"\"\"\n",
    "            Computes the Entropy, or Info(D) [1]\n",
    "        :param labels:\n",
    "        :return: entropy\n",
    "        \"\"\"\n",
    "        entropy = 0.0\n",
    "        class_freq = collections.Counter(labels)  # [4]\n",
    "        for l in class_freq.keys():\n",
    "            p = float(class_freq[l] / len(labels))\n",
    "            entropy = entropy - math.log(p, 2)\n",
    "        return entropy\n",
    "\n",
    "    def information_gain(self, dataset_entropy, attribute_entropy):\n",
    "        \"\"\"\n",
    "            Computes information gain based on the data entropy and attribute entropy [1]\n",
    "        :param dataset_entropy:\n",
    "        :param attribute_entropy:\n",
    "        :return: gain\n",
    "        \"\"\"\n",
    "        gain = dataset_entropy - attribute_entropy\n",
    "        return gain\n",
    "\n",
    "    def split_info(self, p_j):\n",
    "        \"\"\"\n",
    "            Computes the information split, used in gain ratio [1]\n",
    "        :param p_j:\n",
    "        :return: info_split\n",
    "        \"\"\"\n",
    "        # error protection for zero case\n",
    "        if p_j == 0:\n",
    "            return 0\n",
    "\n",
    "        info_split = (p_j * math.log(p_j, 2))\n",
    "        return info_split\n",
    "\n",
    "    def information_gain_ratio(self, gain, split_info):\n",
    "        \"\"\"\n",
    "            Computes information gain ratio [1]\n",
    "        :param gain:\n",
    "        :param split_info:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        gain_ratio = float(gain / split_info)\n",
    "        return gain_ratio\n",
    "\n",
    "    def partition_data(self, D, attribute, val):\n",
    "        \"\"\"\n",
    "            Partitions a dataset D based on the value of a specific attribute\n",
    "        :param D:\n",
    "        :param attribute:\n",
    "        :param val:\n",
    "        :return: part, part_y\n",
    "        \"\"\"\n",
    "        part = D[0].loc[D[0][attribute] == val]\n",
    "        part_idx = D[0].index[D[0][attribute] == val]\n",
    "        part_y = D[1].loc[part_idx]\n",
    "        return part, part_y\n",
    "\n",
    "    def test_tree(self, test_sample, node):\n",
    "        \"\"\"\n",
    "            Using recursion, we go through each node (from the root through to the children) to find a leaf label\n",
    "            to classify the test sample as a prediction.\n",
    "        :param test_sample:\n",
    "        :param node:\n",
    "        :return: node.leaf_label, or recursion\n",
    "        \"\"\"\n",
    "\n",
    "        if node.node_type == 'leaf':\n",
    "            return node.leaf_label\n",
    "        else:\n",
    "            for child in node.children:\n",
    "                if (child.best_attribute is None or child.best_attribute == '') and child.node_type == 'leaf':\n",
    "                    return self.test_tree(test_sample, child)\n",
    "\n",
    "                if (child.best_attribute is None or child.best_attribute == '') and child.node_type == 'node':\n",
    "                    pass\n",
    "                else:\n",
    "                    if child.split_criterion == test_sample[child.best_attribute]:\n",
    "                        return self.test_tree(test_sample, child)\n",
    "                    else:\n",
    "                        if child.split_up_down == 'UP':\n",
    "                            # check if att_val > split_criterion\n",
    "                            if pd.to_numeric(test_sample[child.best_attribute]) > float(child.split_criterion):\n",
    "                                return self.test_tree(test_sample, child)\n",
    "                            else:\n",
    "                                pass\n",
    "                        elif child.split_up_down == 'DOWN':\n",
    "                            if pd.to_numeric(test_sample[child.best_attribute]) <= float(child.split_criterion):\n",
    "                                return self.test_tree(test_sample, child)\n",
    "                            else:\n",
    "                                pass\n",
    "\n",
    "    def predict(self, test_x, test_y):  # TODO Add this functionality from the code in main routine\n",
    "        # uses test set to predict class labels from the constructed tree\n",
    "        preds = []\n",
    "        true_pred = 0\n",
    "        for i in range(len(test_x)):\n",
    "            tester_instance = test_x.iloc[i]\n",
    "            pred = self.test_tree(tester_instance, self.root_node)\n",
    "            # print(str(i), 'pred', pred, 'label', y.iloc[i])\n",
    "            if pred == test_y.iloc[i]:\n",
    "                true_pred += 1\n",
    "            preds.append(pred)\n",
    "\n",
    "        return true_pred, preds\n",
    "\n",
    "    def print_tree(self):\n",
    "        nodes_created = sorted(self.tree_nodes)\n",
    "        for n in nodes_created:\n",
    "            n.print_node()\n",
    "            for d in n.children:\n",
    "                d.print_node()\n",
    "            print()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Train (32561, 15) , Test (16281, 15)\n"
     ]
    }
   ],
   "source": [
    "# Pre-process\n",
    "train_data = pd.read_csv('./adult/adult.data', header= None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'class'])\n",
    "test_data = pd.read_csv('./adult/adult.test', header= None, skiprows=1, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'class'])\n",
    "originTest = test_data\n",
    "\n",
    "print(\"Original: Train\", train_data.shape, \", Test\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Dropping: Train (32537, 15) , Test (16276, 15)\n"
     ]
    }
   ],
   "source": [
    "#刪除重複的值\n",
    "\n",
    "train_data.drop_duplicates(inplace=True)\n",
    "test_data.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"After Dropping: Train\", train_data.shape, \", Test\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education-num      marital-status  \\\n",
       "0   39         State-gov             13       Never-married   \n",
       "1   50  Self-emp-not-inc             13  Married-civ-spouse   \n",
       "2   38           Private              9            Divorced   \n",
       "3   53           Private              7  Married-civ-spouse   \n",
       "4   28           Private             13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital-gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1    Exec-managerial        Husband  White    Male             0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3  Handlers-cleaners        Husband  Black    Male             0   \n",
       "4     Prof-specialty           Wife  Black  Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week native-country  class  \n",
       "0             0              40  United-States  <=50K  \n",
       "1             0              13  United-States  <=50K  \n",
       "2             0              40  United-States  <=50K  \n",
       "3             0              40  United-States  <=50K  \n",
       "4             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# education and education-num have same meaning\n",
    "train_data.drop(['education'], axis = 1, inplace = True)\n",
    "test_data.drop(['education'], axis = 1, inplace = True)\n",
    "\n",
    "# fnlwgt is not important feature\n",
    "train_data.drop(['fnlwgt'], axis = 1, inplace = True)\n",
    "test_data.drop(['fnlwgt'], axis = 1, inplace = True)\n",
    "\n",
    "# remove the space\n",
    "train_data = train_data.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "test_data = test_data.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "# replace the \"?\" into NAN\n",
    "train_data.replace(\"?\", pd.NaT, inplace = True)\n",
    "test_data.replace(\"?\", pd.NaT, inplace = True)\n",
    "\n",
    "# replace the NAN into mode value\n",
    "train_data['workclass'] = train_data['workclass'].replace(float('nan'), train_data['workclass'].mode()[0])\n",
    "train_data['occupation'] = train_data['occupation'].replace(float('nan'),train_data['occupation'].mode()[0])\n",
    "train_data['native-country'] = train_data['native-country'].replace(float('nan'),train_data['native-country'].mode()[0])\n",
    "\n",
    "\n",
    "test_data['workclass'] = test_data['workclass'].replace(float('nan'), test_data['workclass'].mode()[0])\n",
    "test_data['occupation'] = test_data['occupation'].replace(float('nan'),test_data['occupation'].mode()[0])\n",
    "test_data['native-country'] = test_data['native-country'].replace(float('nan'),test_data['native-country'].mode()[0])\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "education-num     0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours-per-week    0\n",
       "native-country    0\n",
       "class             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is Nan or not\n",
    "train_data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding (Dummies)\n",
    "trainData_dum = pd.get_dummies(train_data, columns=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], dtype=int)\n",
    "testData_dum = pd.get_dummies(test_data, columns=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'], dtype=int)\n",
    "pd.DataFrame(trainData_dum)\n",
    "\n",
    "## 數值屬性做Normalization(z-score)\n",
    "numerical_columns = ['age','education-num','capital-gain','capital-loss','hours-per-week']\n",
    "scaler = preprocessing.StandardScaler()\n",
    "trainData_dum[numerical_columns] = scaler.fit_transform(trainData_dum[numerical_columns])\n",
    "testData_dum[numerical_columns] = scaler.fit_transform(testData_dum[numerical_columns])\n",
    "\n",
    "# tranfer the value of class(income) into int(1 or 0)\n",
    "# >50K is 1, <=50K is 0\n",
    "trainData_dum['class'] = trainData_dum['class'].apply(lambda x: 1 if x == \">50K\" else 0)\n",
    "testData_dum['class'] = testData_dum['class'].apply(lambda x: 1 if x == \">50K\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#在讀熱編碼後會依照有名目之欄位產生資料，train_data比test_data多出了該欄位，故將test_data新增該欄位，讓兩個資料集欄位相同。\n",
    "testData_dum['native-country_Holand-Netherlands'] = 0\n",
    "\n",
    "#刪除重複列\n",
    "trainData_dum.drop_duplicates(inplace=True)\n",
    "testData_dum.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>class</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030390</td>\n",
       "      <td>1.134777</td>\n",
       "      <td>0.148292</td>\n",
       "      <td>-0.216743</td>\n",
       "      <td>-0.035664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.836973</td>\n",
       "      <td>1.134777</td>\n",
       "      <td>-0.145975</td>\n",
       "      <td>-0.216743</td>\n",
       "      <td>-2.222483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042936</td>\n",
       "      <td>-0.420679</td>\n",
       "      <td>-0.145975</td>\n",
       "      <td>-0.216743</td>\n",
       "      <td>-0.035664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.056950</td>\n",
       "      <td>-1.198407</td>\n",
       "      <td>-0.145975</td>\n",
       "      <td>-0.216743</td>\n",
       "      <td>-0.035664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.776193</td>\n",
       "      <td>1.134777</td>\n",
       "      <td>-0.145975</td>\n",
       "      <td>-0.216743</td>\n",
       "      <td>-0.035664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education-num  capital-gain  capital-loss  hours-per-week  class  \\\n",
       "0  0.030390       1.134777      0.148292     -0.216743       -0.035664      0   \n",
       "1  0.836973       1.134777     -0.145975     -0.216743       -2.222483      0   \n",
       "2 -0.042936      -0.420679     -0.145975     -0.216743       -0.035664      0   \n",
       "3  1.056950      -1.198407     -0.145975     -0.216743       -0.035664      0   \n",
       "4 -0.776193       1.134777     -0.145975     -0.216743       -0.035664      0   \n",
       "\n",
       "   workclass_Federal-gov  workclass_Local-gov  workclass_Never-worked  \\\n",
       "0                      0                    0                       0   \n",
       "1                      0                    0                       0   \n",
       "2                      0                    0                       0   \n",
       "3                      0                    0                       0   \n",
       "4                      0                    0                       0   \n",
       "\n",
       "   workclass_Private  ...  native-country_Portugal  \\\n",
       "0                  0  ...                        0   \n",
       "1                  0  ...                        0   \n",
       "2                  1  ...                        0   \n",
       "3                  1  ...                        0   \n",
       "4                  1  ...                        0   \n",
       "\n",
       "   native-country_Puerto-Rico  native-country_Scotland  native-country_South  \\\n",
       "0                           0                        0                     0   \n",
       "1                           0                        0                     0   \n",
       "2                           0                        0                     0   \n",
       "3                           0                        0                     0   \n",
       "4                           0                        0                     0   \n",
       "\n",
       "   native-country_Taiwan  native-country_Thailand  \\\n",
       "0                      0                        0   \n",
       "1                      0                        0   \n",
       "2                      0                        0   \n",
       "3                      0                        0   \n",
       "4                      0                        0   \n",
       "\n",
       "   native-country_Trinadad&Tobago  native-country_United-States  \\\n",
       "0                               0                             1   \n",
       "1                               0                             1   \n",
       "2                               0                             1   \n",
       "3                               0                             1   \n",
       "4                               0                             0   \n",
       "\n",
       "   native-country_Vietnam  native-country_Yugoslavia  \n",
       "0                       0                          0  \n",
       "1                       0                          0  \n",
       "2                       0                          0  \n",
       "3                       0                          0  \n",
       "4                       0                          0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>class</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "      <th>native-country_Holand-Netherlands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.994356</td>\n",
       "      <td>-1.196669</td>\n",
       "      <td>-0.142684</td>\n",
       "      <td>-0.218097</td>\n",
       "      <td>-0.031615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.055664</td>\n",
       "      <td>-0.417699</td>\n",
       "      <td>-0.142684</td>\n",
       "      <td>-0.218097</td>\n",
       "      <td>0.769762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.777734</td>\n",
       "      <td>0.750757</td>\n",
       "      <td>-0.142684</td>\n",
       "      <td>-0.218097</td>\n",
       "      <td>-0.031615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377579</td>\n",
       "      <td>-0.028214</td>\n",
       "      <td>0.870916</td>\n",
       "      <td>-0.218097</td>\n",
       "      <td>-0.031615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.499805</td>\n",
       "      <td>-0.028214</td>\n",
       "      <td>-0.142684</td>\n",
       "      <td>-0.218097</td>\n",
       "      <td>-0.832992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education-num  capital-gain  capital-loss  hours-per-week  class  \\\n",
       "0 -0.994356      -1.196669     -0.142684     -0.218097       -0.031615      0   \n",
       "1 -0.055664      -0.417699     -0.142684     -0.218097        0.769762      0   \n",
       "2 -0.777734       0.750757     -0.142684     -0.218097       -0.031615      0   \n",
       "3  0.377579      -0.028214      0.870916     -0.218097       -0.031615      0   \n",
       "4 -1.499805      -0.028214     -0.142684     -0.218097       -0.832992      0   \n",
       "\n",
       "   workclass_Federal-gov  workclass_Local-gov  workclass_Never-worked  \\\n",
       "0                      0                    0                       0   \n",
       "1                      0                    0                       0   \n",
       "2                      0                    1                       0   \n",
       "3                      0                    0                       0   \n",
       "4                      0                    0                       0   \n",
       "\n",
       "   workclass_Private  ...  native-country_Puerto-Rico  \\\n",
       "0                  1  ...                           0   \n",
       "1                  1  ...                           0   \n",
       "2                  0  ...                           0   \n",
       "3                  1  ...                           0   \n",
       "4                  1  ...                           0   \n",
       "\n",
       "   native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "0                        0                     0                      0   \n",
       "1                        0                     0                      0   \n",
       "2                        0                     0                      0   \n",
       "3                        0                     0                      0   \n",
       "4                        0                     0                      0   \n",
       "\n",
       "   native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "0                        0                               0   \n",
       "1                        0                               0   \n",
       "2                        0                               0   \n",
       "3                        0                               0   \n",
       "4                        0                               0   \n",
       "\n",
       "   native-country_United-States  native-country_Vietnam  \\\n",
       "0                             1                       0   \n",
       "1                             1                       0   \n",
       "2                             1                       0   \n",
       "3                             1                       0   \n",
       "4                             1                       0   \n",
       "\n",
       "   native-country_Yugoslavia  native-country_Holand-Netherlands  \n",
       "0                          0                                  0  \n",
       "1                          0                                  0  \n",
       "2                          0                                  0  \n",
       "3                          0                                  0  \n",
       "4                          0                                  0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full set test accuracy: 0.9243243243243243\n"
     ]
    }
   ],
   "source": [
    "# put \"class\" to the last column\n",
    "td = trainData_dum\n",
    "column = td.pop(\"class\")\n",
    "td.insert(td.shape[1], \"class\", column)\n",
    "\n",
    "columns = td.columns.tolist()\n",
    "\n",
    "X_train = td.drop('class', axis=1)\n",
    "y_train = td['class']\n",
    "\n",
    "ted = testData_dum\n",
    "t_column = ted.pop(\"class\")\n",
    "ted.insert(ted.shape[1], \"class\", t_column)\n",
    "\n",
    "X_test = ted.drop('class', axis=1)\n",
    "y_test = ted['class']\n",
    "\n",
    "\n",
    "#C4.5\n",
    "system_test = C45Tree(columns, td)\n",
    "system_test.train(X_train, y_train)\n",
    "true_pred, preds = system_test.predict(X_test, y_test)\n",
    "\n",
    "print('Full set test accuracy:', true_pred / len(X_test))\n",
    "\n",
    "# print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸出混亂矩陣，顯示準確率：使用驗證資料\n",
      "[[13851  1134]\n",
      " [    0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96     14985\n",
      "           1       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92     14985\n",
      "   macro avg       0.50      0.96      0.48     14985\n",
      "weighted avg       1.00      0.92      0.96     14985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#輸出混亂矩陣，顯示準確率\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(\"輸出混亂矩陣，顯示準確率：使用驗證資料\")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "## 一般情況zero_division會設1(true)，除非確定每個類別都有被預測到才會設0\n",
    "print(classification_report(y_test, preds, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXCEL 輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將 R 的預測結果轉換為 Python 陣列\n",
    "#rpy2\n",
    "from openpyxl import Workbook\n",
    "\n",
    "#產出Excel(Test data)\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.append(['age', 'workclass', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'class', 'Predict result'])\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] == 0:\n",
    "        result = '<=50K.'\n",
    "    else:\n",
    "        result = '>50K.'\n",
    "    #將現在loop到原始資料的列轉為list\n",
    "    li = originTest.iloc[i,:].tolist()\n",
    "    #\n",
    "    li.append(result)\n",
    "    ws.append(li)\n",
    "wb.save('C45.xlsx')\n",
    "# predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Node： 113\n",
      "Leaf Node： 54\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Node：\", len(system_test.tree_nodes))\n",
    "leaf_count = 0\n",
    "for n in system_test.tree_nodes:\n",
    "    # print(n.print_node())\n",
    "    if n.node_type == 'leaf':\n",
    "        leaf_count += 1\n",
    "\n",
    "print(\"Leaf Node：\", leaf_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.read_csv(\"adult/adult.test\", header= None, names=['age', 'workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "# test_data.drop(0,axis=0,inplace=True)\n",
    "# #刪除重複的值\n",
    "# test_data_new = test_data.drop_duplicates()\n",
    "\n",
    "# preds_label = []\n",
    "# for i in range(len(preds)):\n",
    "#     if(preds[i]==0):\n",
    "#         preds_label.append(\"<=50K\")\n",
    "#     else:\n",
    "#         preds_label.append(\">50K\")\n",
    "# preds_label = pd.DataFrame(preds_label)\n",
    "# result = pd.concat([test_data_new, preds_label], axis=1)\n",
    "# result.to_csv(\"adult_C45.csv\",header=['age', 'workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income','income_predict'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get importance\n",
    "# importance = system_test.feature_importances_\n",
    "# # summarize feature importance\n",
    "# for i,v in enumerate(importance):\n",
    "# \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# # plot feature importance\n",
    "# pyplot.bar([x for x in range(len(importance))], importance)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# #以圖表事每個特徵變數的重要程度(0最小，1最大)\n",
    "# def plot_feature_importances_cancer(model):\n",
    "#     n_features = X_train.shape[1]\n",
    "#     plt.figure(figsize=(15,30))\n",
    "#     plt.barh(np.arange(n_features), model.feature_importances_, align='center')\n",
    "#     plt.yticks(np.arange(n_features), train_x.columns)\n",
    "#     plt.xlabel(\"Feature importance\")\n",
    "#     plt.ylabel(\"Feature\")\n",
    "#     plt.ylim(-1, n_features)\n",
    "\n",
    "# plot_feature_importances_cancer(system_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
